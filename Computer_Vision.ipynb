{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer Vision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyeseong0317/Learning-Tensorflow-MachineLearning/blob/main/Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_o2L3Io9t4c"
      },
      "source": [
        "#Deep Computer Vision\n",
        "\n",
        "In this guide we will learn how to peform *image classification and object detection/recognition* using deep computer vision with something called a **convolutional neural network**.\n",
        "\n",
        "The goal of our convolutional neural networks will be to classify and detect images or specific objects from within the image. We will be using image data as our features and a label for those images as our label or output.\n",
        "\n",
        "We already know how neural networks work so we can skip through the basics and move right into explaining the following concepts.\n",
        "- Image Data\n",
        "- Convolutional Layer\n",
        "- Pooling Layer\n",
        "- CNN Architectures\n",
        "\n",
        "The major differences we are about to see in these types of neural networks are the layers that make them up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdqlqfhLCHZl"
      },
      "source": [
        "##Image Data\n",
        "So far, we have dealt with pretty straight forward data that has 1 or 2 dimensions. Now we are about to deal with image data that is usually made up of 3 dimensions. These 3 dimensions are as follows:\n",
        "- image height\n",
        "- image width\n",
        "- color channels\n",
        "\n",
        "The only item in the list above you may not understand is **color channels**. The number of color channels represents the depth of an image and coorelates to the colors used in it. For example, an image with three channels is likely made up of rgb (red, green, blue) pixels. So, for each pixel we have three numeric values in the range 0-255 that define its color. For an image of color depth 1 we would likely have a greyscale image with one value defining each pixel, again in the range of 0-255.\n",
        "\n",
        "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure1.png)\n",
        "\n",
        "Keep this in mind as we discuss how our network works and the input/output of each layer. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mqznmTh--v2"
      },
      "source": [
        "##Convolutional Neural Network\n",
        "**Note:** I will use the term *convnet* and convolutional neural network interchangably.\n",
        "\n",
        "Each convolutional neural network is made up of one or many convolutional layers. These layers are different than the *dense* layers we have seen previously. Their goal is to find patterns from within images that can be used to classify the image or parts of it. But this may sound familiar to what our densly connected neural network in the previous section was doing, well that's becasue it is. \n",
        "\n",
        "The fundemental difference between a dense layer and a convolutional layer is that dense layers detect patterns globally while convolutional layers detect patterns locally. When we have a densly connected layer each node in that layer sees all the data from the previous layer. This means that this layer is looking at all the information and is only capable of analyzing the data in a global capacity. Our convolutional layer however will not be densly connected, this means it can detect local patterns using part of the input data to that layer.\n",
        "\n",
        "*Let's have a look at how a densly connected layer would look at an image vs how a convolutional layer would.*\n",
        "\n",
        "This is our image; the goal of our network will be to determine whether this image is a cat or not.\n",
        "![alt text](https://img.webmd.com/dtmcms/live/webmd/consumer_assets/site_images/article_thumbnails/reference_guide/cat_weight_ref_guide/1800x1200_cat_weight_ref_guide.jpg)\n",
        "\n",
        "**Dense Layer:** A dense layer will consider the ENTIRE image. It will look at all the pixels and use that information to generate some output.\n",
        "\n",
        "**Convolutional Layer:** The convolutional layer will look at specific parts of the image. In this example let's say it analyzes the highlighted parts below and detects patterns there.\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1M7v7S-b-zisFLI_G4ZY_RdUJQrGpJ3zt)\n",
        "\n",
        "Can you see why this might make these networks more useful?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-y_8rdpRZ2J"
      },
      "source": [
        "### ***With the dense neural network***\r\n",
        "It would find these features, it would learn them, learn these patterns, only learn them only in this specific area where the box stop which means if I horizontally flip this image, then it's not going to know that's a cat because it learns that pattern in this specific area, it'll need to relearn that pattern in the other area\r\n",
        "### ***The convolutional neural network, on the other hand, learns local patterns.***\r\n",
        "So rather than learning that ear exists in the specific location, it just learns that this is what an ear looks like and it can find that anywhere in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIQvxFu_FB3h"
      },
      "source": [
        "###How They Work\n",
        "A dense neural network learns patterns that are present in one specific area of an image. This means if a pattern that the network knows is present in a different area of the image it will have to learn the pattern again in that new area to be able to detect it. \n",
        "\n",
        "*Let's use an example to better illustrate this.*\n",
        "\n",
        "We'll consider that we have a dense neural network that has learned what an eye looks like from a sample of dog images.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=16FJKkVS_lZToQOCOOy6ohUpspWgtoQ-c)\n",
        "\n",
        "Let's say it's determined that an image is likely to be a dog if an eye is present in the boxed off locations of the image above.\n",
        "\n",
        "Now let's flip the image.\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1V7Dh7BiaOvMq5Pm_jzpQfJTZcpPNmN0W)\n",
        "\n",
        "Since our densly connected network has only recognized patterns globally it will look where it thinks the eyes should be present. Clearly it does not find them there and therefore would likely determine this image is not a dog. Even though the pattern of the eyes is present, it's just in a different location.\n",
        "\n",
        "Since convolutional layers learn and detect patterns from different areas of the image, they don't have problems with the example we just illustrated. They know what an eye looks like and by analyzing different parts of the image can find where it is present. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20J29gz-NroA"
      },
      "source": [
        "###Multiple Convolutional Layers\n",
        "In our models it is quite common to have more than one convolutional layer. Even the basic example we will use in this guide will be made up of 3 convolutional layers. These layers work together by increasing complexity and abstraction at each subsequent layer. The first layer might be responsible for picking up edges and short lines, while the second layer will take as input these lines and start forming shapes or polygons. Finally, the last layer might take these shapes and determine which combiantions make up a specific image.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii-a9rXzRwNi"
      },
      "source": [
        "##Feature Maps\n",
        "You may see me use the term *feature map* throughout this tutorial. This term simply stands for a 3D tensor with two spacial axes (width and height) and one depth axis. Our convolutional layers take feature maps as their input and return a new feature map that reprsents the prescence of spcific filters from the previous feature map. These are what we call *response maps*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OScABB-ScXHx"
      },
      "source": [
        "##Layer Parameters\n",
        "A convolutional layer is defined by two key parameters.\n",
        "\n",
        "####**Filters**\n",
        "A filter is a m x n pattern of pixels that we are looking for in an image. The number of filters in a convolutional layer reprsents how many patterns each layer is looking for and what the depth of our response map will be. If we are looking for 32 different patterns/filters than our output feature map (aka the response map) will have a depth of 32. Each one of the 32 layers of depth will be a matrix of some size containing values indicating if the filter was present at that location or not.\n",
        "\n",
        "Here's a great illustration from the book \"Deep Learning with Python\" by Francois Chollet (pg 124).\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1HcLvvLKvLCCGuGZPMvKYz437FbbCC2eB)\n",
        "\n",
        "####**Sample Size**\n",
        "This isn't really the best term to describe this, but each convolutional layer is going to examine n x m blocks of pixels in each image. Typically, we'll consider 3x3 or 5x5 blocks. In the example above we use a 3x3 \"sample size\". This size will be the same as the size of our filter. \n",
        "\n",
        "Our layers work by sliding these filters of n x m pixels over every possible position in our image and populating a new feature map/response map indicating whether the filter is present at each location. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXVxK33NU9AP"
      },
      "source": [
        "### **The filter is what's going to be changed**\r\n",
        "This filter is actually what is going to be found by the neural network. It's what's going to change. This is essentailly what we're looking for, this what's created from the program and that's kind of like the **trainable parameter** of a convolutional neural network is the **filter.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnzqr8Dzjchd"
      },
      "source": [
        "##Borders and Padding\n",
        "The more mathematical of you may have realized that if we slide a filter of let's say size 3x3 over our image well consider less positions for our filter than pixels in our input. Look at the example below. \n",
        "\n",
        "*Image from \"Deep Learning with Python\" by Francois Chollet (pg 126).*\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1OEfXrV16NBjwAafgBfYYcWOyBCHqaZ5M)\n",
        "\n",
        "This means our response map will have a slightly smaller width and height than our original image. This is fine but sometimes we want our response map to have the same dimensions. We can accomplish this by using something called *padding*.\n",
        "\n",
        "**Padding** is simply the addition of the appropriate number of rows and/or columns to your input data such that each pixel can be centered by the filter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDwH2eOMmt_N"
      },
      "source": [
        "##Strides\n",
        "In the previous sections we assumed that the filters would be slid continously through the image such that it covered every possible position. This is common but sometimes we introduce the idea of a **stride** to our convolutional layer. The stride size reprsents how many rows/cols we will move the filter each time. These are not used very frequently so we'll move on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCsVC-4UnfC8"
      },
      "source": [
        "##Pooling\n",
        "You may recall that our convnets are made up of a stack of convolution and pooling layers.\n",
        "\n",
        "The idea behind a pooling layer is to downsample our feature maps and reduce their dimensions. They work in a similar way to convolutional layers where they extract windows from the feature map and return a response map of the max, min or average values of each channel. Pooling is usually done using windows of size 2x2 and a stride of 2. This will reduce the size of the feature map by a factor of two and return a response map that is 2x smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qo85O0LsxbB"
      },
      "source": [
        "##A More Detailed Look\n",
        "Please refer to the video to learn how all of this happens at the lower level! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqLsm2XzNQSE"
      },
      "source": [
        "##Creating a Convnet\n",
        "\n",
        "Now it is time to create our first convnet! This example is for the purpose of getting familiar with CNN architectures, we will talk about how to improves its performance later.\n",
        "\n",
        "*This tutorial is based on the following guide from the TensorFlow documentation: https://www.tensorflow.org/tutorials/images/cnn*\n",
        "\n",
        "###Dataset\n",
        "The problem we will consider here is classifying 10 different everyday objects. The dataset we will use is built into tensorflow and called the [**CIFAR Image Dataset.**](https://www.cs.toronto.edu/~kriz/cifar.html) It contains 60,000 32x32 color images with 6000 images of each class. \n",
        "\n",
        "The labels in this dataset are the following:\n",
        "- Airplane\n",
        "- Automobile\n",
        "- Bird\n",
        "- Cat\n",
        "- Deer\n",
        "- Dog\n",
        "- Frog\n",
        "- Horse\n",
        "- Ship\n",
        "- Truck\n",
        "\n",
        "We'll load the dataset and have a look at some of the images below.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnIbwiK7Ohv2",
        "outputId": "8e1bd1fa-d954-480f-bf09-a57ac30b5334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49wbEaM1PCCR",
        "outputId": "b8c07b68-0443-4c70-9827-e435747cabd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#  LOAD AND SPLIT DATASET\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0 # 0~1로 normalization 합니다, 256 사이즈보다 다루기 쉬워집니다\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp0yAAcuPHFN",
        "outputId": "0a000cbe-2255-4cd9-dc26-77eef6afcea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# Let's look at a one image\n",
        "IMG_INDEX = 7  # change this to look at other images\n",
        "\n",
        "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPqeddhcPwpc"
      },
      "source": [
        "##CNN Architecture\n",
        "A common architecture for a CNN is a stack of Conv2D and MaxPooling2D layers followed by a few denesly connected layers. To idea is that the stack of convolutional and maxPooling layers extract the features from the image. Then these features are flattened and fed to densly connected layers that determine the class of an image based on the presence of features.\n",
        "\n",
        "We will start by building the **Convolutional Base**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibuJZqAXQrWJ"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2))) # 2x2 filter, strides = 2 \n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tybTBoi_Qtxl"
      },
      "source": [
        "**Layer 1**\n",
        "\n",
        "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
        "\n",
        "**Layer 2**\n",
        "\n",
        "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
        "\n",
        "**Other Layers**\n",
        "\n",
        "The next set of layers do very similar things but take as input the feature map from the previous layer. They also increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QahwuduSEDG",
        "outputId": "840dcb45-7a95-429a-9526-9b1c670e9eb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()  # let's have a look at our model so far, padding을 하지 않았으므로 이미지 사이즈가 줄어들어 conv2d_3의 Output Shape가 32x32x32가 아닌 2가 줄어든 30x30x32입니다"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 56,320\n",
            "Trainable params: 56,320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXw-sreaSzTW"
      },
      "source": [
        "After looking at the summary you should notice that the depth of our image increases but the spacial dimensions reduce drastically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjtADcfmSI9q"
      },
      "source": [
        "##Adding Dense Layers\n",
        "So far, we have just completed the **convolutional base**. Now we need to take these extracted features and add a way to classify them. This is why we add the following layers to our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9TMZH_oSULo"
      },
      "source": [
        "model.add(layers.Flatten()) # coonv2d_5 4x4x64를 1024의 1 Dimension으로 만듭니다\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEzHX-7ESeCl",
        "outputId": "c8ff07c0-aab2-4a82-a8c2-27d8916cae44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 123,924\n",
            "Trainable params: 123,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxfqtdDbSf4W"
      },
      "source": [
        "We can see that the flatten layer changes the shape of our data so that we can feed it to the 64-node dense layer, follwed by the final output layer of 10 neurons (one for each class).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPxFvHdTLRK"
      },
      "source": [
        "##Training\n",
        "Now we will train and compile the model using the recommended hyper paramaters from tensorflow.\n",
        "\n",
        "*Note: This will take much longer than previous models!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5loIug93TW1E",
        "outputId": "ee31c549-bb28-47ed-e58b-a559db540b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=4, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 1.8137 - accuracy: 0.3209 - val_loss: 1.2949 - val_accuracy: 0.5294\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 1.2497 - accuracy: 0.5491 - val_loss: 1.1217 - val_accuracy: 0.6011\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 1.0480 - accuracy: 0.6267 - val_loss: 1.0091 - val_accuracy: 0.6490\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.9222 - accuracy: 0.6693 - val_loss: 0.9958 - val_accuracy: 0.6510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdRKQnETgLv"
      },
      "source": [
        "##Evaluating the Model\n",
        "We can determine how well the model performed by looking at it's performance on the test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I2vJFiiTkQE",
        "outputId": "414dc937-8c0c-460e-b223-2fa5759562e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 3s - loss: 0.9958 - accuracy: 0.6510\n",
            "0.6510000228881836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lKwDlvvUbIm"
      },
      "source": [
        "You should be getting an accuracy of about 70%. This isn't bad for a simple model like this, but we'll dive into some better approaches for computer vision below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstpZFVaY7YH"
      },
      "source": [
        "##Working with Small Datasets\n",
        "In the situation where you don't have millions of images it is difficult to train a CNN from scratch that performs very well. This is why we will learn about a few techniques we can use to train CNN's on small datasets of just a few thousand images. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D4iWJ17ZRt_"
      },
      "source": [
        "###Data Augmentation\n",
        "To avoid overfitting and create a larger dataset from a smaller one we can use a technique called data augmentation. This is simply performing random transofrmations on our images so that our model can generalize better. These transformations can be things like compressions, rotations, stretches and even color changes. \n",
        "\n",
        "Fortunately, keras can help us do this. Look at the code below to an example of data augmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sOet0hQZ-gR"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# creates a data generator object that transforms images\n",
        "datagen = ImageDataGenerator(\n",
        "rotation_range=40,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True,\n",
        "fill_mode='nearest')\n",
        "\n",
        "# pick an image to transform\n",
        "test_img = train_images[20]\n",
        "img = image.img_to_array(test_img)  # convert image to numpy arry\n",
        "img = img.reshape((1,) + img.shape)  # reshape image\n",
        "\n",
        "i = 0\n",
        "\n",
        "for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):  # this loops runs forever until we break, saving images to current directory with specified prefix\n",
        "    plt.figure(i)\n",
        "    plot = plt.imshow(image.img_to_array(batch[0])) # batch[0]는 첫번째 이미지\n",
        "    i += 1\n",
        "    if i > 4:  # show 4 images\n",
        "        break\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc9RyHPYUnSK"
      },
      "source": [
        "###Pretrained Models\n",
        "You would have noticed that the model above takes a few minutes to train in the NoteBook and only gives an accuaracy of ~70%. This is okay but surely there is a way to improve on this. \n",
        "\n",
        "In this section we will talk about using a pretrained CNN as apart of our own custom network to improve the accuracy of our model. We know that CNN's alone (with no dense layers) don't do anything other than map the presence of features from our input. This means we can use a pretrained CNN, one trained on millions of images, as the start of our model. This will allow us to have a very good convolutional base before adding our own dense layered classifier at the end. In fact, by using this techique we can train a very good classifier for a realtively small dataset (< 10,000 images). This is because the convnet already has a very good idea of what features to look for in an image and can find them very effectively. So, if we can determine the presence of features all the rest of the model needs to do is determine which combination of features makes a specific image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u10oZO1oXT6Y"
      },
      "source": [
        "###Fine Tuning\n",
        "When we employ the technique defined above, we will often want to tweak the final layers in our convolutional base to work better for our specific problem. This involves not touching or retraining the earlier layers in our convolutional base but only adjusting the final few. We do this because the first layers in our base are very good at extracting low level features lile lines and edges, things that are similar for any kind of image. Where the later layers are better at picking up very specific features like shapes or even eyes. If we adjust the final layers than we can look for only features relevant to our very specific problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XolyariNdj5p"
      },
      "source": [
        "##Using a Pretrained Model\n",
        "In this section we will combine the tecniques we learned above and use a pretrained model and fine tuning to classify images of dogs and cats using a small dataset.\n",
        "\n",
        "*This tutorial is based on the following guide from the TensorFlow documentation: https://www.tensorflow.org/tutorials/images/transfer_learning*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nRe9qWmgxm7"
      },
      "source": [
        "#Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "keras = tf.keras"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUx4I_4jg2Tc"
      },
      "source": [
        "###Dataset\n",
        "We will load the *cats_vs_dogs* dataset from the modoule tensorflow_datatsets.\n",
        "\n",
        "This dataset contains (image, label) pairs where images have different dimensions and 3 color channels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuGu50NlgreO",
        "outputId": "260e82d5-13d2-4665-acd5-ade5d9c7db81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# split the data manually into 80% training, 10% testing, 10% validation\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset cats_vs_dogs/4.0.0 (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/cats_vs_dogs/4.0.0.incompleteFZE047/cats_vs_dogs-train.tfrecord\n",
            "\u001b[1mDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_MpiQyh-as"
      },
      "source": [
        "get_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels\n",
        "\n",
        "# display 2 images from the dataset\n",
        "for image, label in raw_train.take(5):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdodmcYiPOF"
      },
      "source": [
        "###Data Preprocessing\n",
        "Since the sizes of our images are all different, we need to convert them all to the same size. We can create a function that will do that for us below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcoKn1VUieqx"
      },
      "source": [
        "IMG_SIZE = 160 # All images will be resized to 160x160\n",
        "\n",
        "def format_example(image, label):\n",
        "  \"\"\"\n",
        "  returns an image that is reshaped to IMG_SIZE\n",
        "  \"\"\"\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image, label"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwIB21lailXh"
      },
      "source": [
        "Now we can apply this function to all our images using ```.map()```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E8iqYOAipdU"
      },
      "source": [
        "train = raw_train.map(format_example)\n",
        "validation = raw_validation.map(format_example)\n",
        "test = raw_test.map(format_example)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QORLTVNaiqym"
      },
      "source": [
        "Let's have a look at our images now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU5JIa2Jiv9U"
      },
      "source": [
        "for image, label in train.take(2):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFnFVaNQi7Vq"
      },
      "source": [
        "Finally we will shuffle and batch the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ZIhkFPi_Pb"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "test_batches = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QxI-fOAjDzC"
      },
      "source": [
        "Now if we look at the shape of an original image vs the new image we will see it has been changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyqrCYNOjY9v",
        "outputId": "6f8cc11b-21df-4008-b790-0e55c30dc903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for img, label in raw_train.take(2):\n",
        "  print(\"Original shape:\", img.shape)\n",
        "\n",
        "for img, label in train.take(2):\n",
        "  print(\"New shape:\", img.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape: (262, 350, 3)\n",
            "Original shape: (409, 336, 3)\n",
            "New shape: (160, 160, 3)\n",
            "New shape: (160, 160, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMpKJ3Xbj4BW"
      },
      "source": [
        "###Picking a Pretrained Model\n",
        "The model we are going to use as the convolutional base for our model is the **MobileNet V2** developed at Google. This model is trained on 1.4 million images and has 1000 different classes.\n",
        "\n",
        "We want to use this model but only its convolutional base. So, when we load in the model, we'll specify that we don't want to load the top (classification) layer. We'll tell the model what input shape to expect and to use the predetermined weights from *imagenet* (Googles dataset).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a09os6dkokI"
      },
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, # tf.keras.applications.MobileNetV2 <- architecture of the model\n",
        "                                               include_top=False, # !! Do we include the classifier that comes with this network or not? !!, 우리는 Dog vs Cat만 구별할것이므로 원래 모델의 1000 classes classifier를 사용하지 않습니다\n",
        "                                               weights='imagenet') "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRvMuWoFR2CO",
        "outputId": "cd472236-4814-428d-ad70-f79c7c2c0323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mobilenetv2_1.00_160\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 80, 80, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 80, 80, 32)   128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 80, 80, 32)   0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 80, 80, 32)   288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 80, 80, 32)   128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 80, 80, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 80, 80, 16)   512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 80, 80, 16)   64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 80, 80, 96)   1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 80, 80, 96)   384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 80, 80, 96)   0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 81, 81, 96)   0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 40, 40, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 40, 40, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 40, 40, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 40, 40, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 40, 40, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 40, 40, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 40, 40, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 40, 40, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 40, 40, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 40, 40, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 40, 40, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 40, 40, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 40, 40, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 41, 41, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 20, 20, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 20, 20, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 20, 20, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 20, 20, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 20, 20, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 20, 20, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 20, 20, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 20, 20, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 20, 20, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 20, 20, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 20, 20, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 20, 20, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 20, 20, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 20, 20, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 21, 21, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 10, 10, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 10, 10, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 10, 10, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 10, 10, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 10, 10, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 10, 10, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 10, 10, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 10, 10, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 10, 10, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 10, 10, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 10, 10, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 10, 10, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 10, 10, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 10, 10, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 10, 10, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 10, 10, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 10, 10, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 10, 10, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 10, 10, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 10, 10, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 10, 10, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 10, 10, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 10, 10, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 10, 10, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 10, 10, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 10, 10, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 10, 10, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 10, 10, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 10, 10, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 10, 10, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 10, 10, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 10, 10, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 10, 10, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 11, 11, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 5, 5, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 5, 5, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 5, 5, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 5, 5, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 5, 5, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 5, 5, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 5, 5, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 5, 5, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 5, 5, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 5, 5, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 5, 5, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 5, 5, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 5, 5, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 5, 5, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 5, 5, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 5, 5, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 5, 5, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 5, 5, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 5, 5, 1280)   0           Conv_1_bn[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 2,223,872\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yihprC2FCPTk"
      },
      "source": [
        "위 코드 실행문에서 out이 (None, 5, 5, 1280)으로 나옵니다. 저희가 input이 무엇인지 모르는 경우 None으로 표시됩니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckYqfl7Vky3S"
      },
      "source": [
        "At this point this *base_model* will simply output a shape (32, 5, 5, 1280) tensor that is a feature extraction from our original (1, 160, 160, 3) image. The 32 means that we have 32 layers of differnt filters/features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yojo6ONzlFGF",
        "outputId": "12a34723-7580-46e1-c3ba-fae59c1f1f87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for image, _ in train_batches.take(1):\n",
        "   pass\n",
        "\n",
        "feature_batch = base_model(image)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 5, 5, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ2kn1P_lhsg"
      },
      "source": [
        "###Freezing the Base\n",
        "The term **freezing** refers to disabling the training property of a layer. It simply means we won’t make any changes to the weights of any layers that are frozen during training. This is important as we don't want to change the convolutional base that already has learned weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hXctqtYl8o5"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jIGFXOrl9wc",
        "outputId": "3fcbe62f-1a15-4f12-afc8-2e5fde1c3c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mobilenetv2_1.00_160\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 80, 80, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 80, 80, 32)   128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 80, 80, 32)   0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 80, 80, 32)   288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 80, 80, 32)   128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 80, 80, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 80, 80, 16)   512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 80, 80, 16)   64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 80, 80, 96)   1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 80, 80, 96)   384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 80, 80, 96)   0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 81, 81, 96)   0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 40, 40, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 40, 40, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 40, 40, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 40, 40, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 40, 40, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 40, 40, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 40, 40, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 40, 40, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 40, 40, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 40, 40, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 40, 40, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 40, 40, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 40, 40, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 41, 41, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 20, 20, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 20, 20, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 20, 20, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 20, 20, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 20, 20, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 20, 20, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 20, 20, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 20, 20, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 20, 20, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 20, 20, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 20, 20, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 20, 20, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 20, 20, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 20, 20, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 21, 21, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 10, 10, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 10, 10, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 10, 10, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 10, 10, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 10, 10, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 10, 10, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 10, 10, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 10, 10, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 10, 10, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 10, 10, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 10, 10, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 10, 10, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 10, 10, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 10, 10, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 10, 10, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 10, 10, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 10, 10, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 10, 10, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 10, 10, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 10, 10, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 10, 10, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 10, 10, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 10, 10, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 10, 10, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 10, 10, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 10, 10, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 10, 10, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 10, 10, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 10, 10, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 10, 10, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 10, 10, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 10, 10, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 10, 10, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 11, 11, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 5, 5, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 5, 5, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 5, 5, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 5, 5, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 5, 5, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 5, 5, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 5, 5, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 5, 5, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 5, 5, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 5, 5, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 5, 5, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 5, 5, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 5, 5, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 5, 5, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 5, 5, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 5, 5, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 5, 5, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 5, 5, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 5, 5, 1280)   0           Conv_1_bn[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3NeXsL9C7JE"
      },
      "source": [
        "Base model을 freeze해서 Trainable parameters를 0으로 만듭니다. 이를 통해 이 모델의 변수는 우리의 모델을 fine tunning할때 변하지 않게 만듭니다. 즉, 저희가 가져다쓰는 모델에 대해서는 이미 잘 만들어진 모델이므로 변수가 변하지 않게 하는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7UJLbJ7mJzw"
      },
      "source": [
        "###Adding our Classifier\n",
        "Now that we have our base layer setup, we can add the classifier. Instead of flattening the feature map of the base layer we will use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1280 element vector per filter.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uUwG5wrnFD6"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejxd7rjInIRp"
      },
      "source": [
        "Finally, we will add the predicition layer that will be a single dense neuron. We can do this because we only have two classes to predict for.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA-iVZj9nH_N"
      },
      "source": [
        "prediction_layer = keras.layers.Dense(1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn9G9KiFnXu6"
      },
      "source": [
        "Now we will combine these layers together in a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_IJucQNnXBK"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLYdAL2uSt_a",
        "outputId": "123969c6-755c-49fb-eab8-8f7010c89ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpQeXNcZEANK"
      },
      "source": [
        "우리의 모델은 1280 neuron과 1개의 output neuron 총 1281개 Trainable parameters가 존재하게 됩니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHepCsPXnpYZ"
      },
      "source": [
        "###Training the Model\n",
        "Now we will train and compile the model. We will use a very small learning rate to ensure that the model does not have any major changes made to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQhg2WxHnxra"
      },
      "source": [
        "base_learning_rate = 0.0001 # major change를 원하지 않으므로 lr를 작게 설정합니다\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fx9nySdoZuL",
        "outputId": "58e053f4-079f-4114-ae65-6caf6d178a22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We can evaluate the model right now to see how it does before training it on our new images\n",
        "initial_epochs = 3\n",
        "validation_steps=20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 12s 526ms/step - loss: 0.7435 - accuracy: 0.4924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edMXObctojl6",
        "outputId": "fbb3b42d-4a06-49e0-a48f-5ed29b9f7cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now we can train it on our images\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_batches)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "print(acc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "582/582 [==============================] - 349s 591ms/step - loss: 0.2144 - accuracy: 0.9068 - val_loss: 0.0876 - val_accuracy: 0.9690\n",
            "Epoch 2/3\n",
            "582/582 [==============================] - 344s 588ms/step - loss: 0.0748 - accuracy: 0.9723 - val_loss: 0.0643 - val_accuracy: 0.9738\n",
            "Epoch 3/3\n",
            "582/582 [==============================] - 354s 606ms/step - loss: 0.0600 - accuracy: 0.9774 - val_loss: 0.0561 - val_accuracy: 0.9794\n",
            "[0.9068242907524109, 0.9722729921340942, 0.9773777723312378]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUUt3AxA2lf2"
      },
      "source": [
        "model.save(\"dogs_vs_cats.h5\")  # we can save the model and reload it at anytime in the future\n",
        "new_model = tf.keras.models.load_model('dogs_vs_cats.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2095EQ4Y3qJk"
      },
      "source": [
        "And that's it for this section on computer vision!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8YcdmWUvYae"
      },
      "source": [
        "##Object Detection\n",
        "If you'd like to learn how you can perform object detection and recognition with tensorflow check out the guide below.\n",
        "\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEiX-D2f2tvI"
      },
      "source": [
        "##Sources\n",
        "1. “Convolutional Neural Network (CNN) &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/images/cnn.\n",
        "2. “Transfer Learning with a Pretrained ConvNet &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/images/transfer_learning.\n",
        "3. Chollet François. Deep Learning with Python. Manning Publications Co., 2018.\n",
        "\n"
      ]
    }
  ]
}